{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d540576",
   "metadata": {},
   "source": [
    "# Graduate Coffee Roulette Algorithm\n",
    "\n",
    "## Business Problem\n",
    "- During COVID-19 Lockdowns, people were feeling lack of connection\n",
    "- People found it hard meeting new people when working from home\n",
    "\n",
    "## Proposed Solution\n",
    "- Coffee Roulette, a progam where Graduates meet a new team member every week for four weeks\n",
    "- Random assignment of mentors to Graduates is easier than cold emailing/messaging\n",
    "- Asking Graudates which topics and service lines they are interested in to make effective matches\n",
    "\n",
    "## Technical Solution\n",
    "A technical solution was required to get the most out of the program without taking an unreasonable amount of someones time to coordinate a roster. The technical solution invovled just two high level steps:\n",
    "- Use Microsoft Forms to collect information on participants interests, service lines and levels\n",
    "- Use Python to take the data and automate the rostering based desired metrics:\n",
    " - Overlap of interests\n",
    " - Diversity of levels\n",
    " - Ensuring all mentors involved\n",
    "\n",
    "### Python Program Overview\n",
    "- Read in the structured data from Microsoft Form's Excel output\n",
    "- Created Bi-Partite Network using NetworkX\n",
    "- Weighted the edges according to optimise desired metrics\n",
    "- Find the optimal matching to minimise the edge weights\n",
    "- Repeat\n",
    "- Output the results\n",
    "\n",
    "## Outcome\n",
    "- 45 Graduates met with 4 mentors each\n",
    "- Both annecdotal evidence and survey results showed the program was appreciated\n",
    "- Graduate Committee was asked to repeat the activity again the following year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f658c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3842338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coffee_Roulette():    \n",
    "    def __init__(self, filename):\n",
    "        # stored properties\n",
    "        self.filename = None\n",
    "        self.header = ['ID', 'Name', 'Group', 'Service_Line', 'Level', 'Interests', 'Service_Line_Preference']\n",
    "        self.data = None\n",
    "        self.people_dict = dict()\n",
    "        self.G = None\n",
    "        self.matches = list()\n",
    "        self.graduates = list()\n",
    "        self.mentors = list()\n",
    "        self.num_matches = 0\n",
    "        self.output_headers = ['Week', 'Graduate', 'Mentor', 'Service Line', 'Level', 'Shared interests', 'Preferred service line']\n",
    "\n",
    "        # default edge weighting parameters\n",
    "        self.interest_weight = 1.0\n",
    "        self.interest_met_weight = 0.5\n",
    "        self.service_line_weight = 1.0\n",
    "        self.service_line_met_weight = 0.5\n",
    "        self.level_matched_penalty = 0.6\n",
    "        self.lonely_mentor_weight = 2.0\n",
    "\n",
    "        self.load_file(filename)\n",
    "        self.initiate_people_dict()\n",
    "        self.initiate_graph()\n",
    "\n",
    "    \n",
    "    def load_file(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "        # read data in as list of lists\n",
    "        with open(self.filename, 'r', encoding='utf8') as fh:\n",
    "            reader = csv.reader(fh, delimiter = ',')\n",
    "            file_header = next(reader)\n",
    "\n",
    "            # account for the strange reading of \"ID\" in the csv file\n",
    "            if self.header != [\"ID\" if \"ID\" in word else word for word in file_header]:\n",
    "                raise Exception('Unexpected header row. Expecting:\\n\"'+', '.join(self.header)+'\".')\n",
    "            \n",
    "            self.data = [row for row in reader]\n",
    "\n",
    "            \n",
    "    def initiate_people_dict(self):\n",
    "        people = [\n",
    "            {self.header[i]: row[i] for i, _ in enumerate(self.header)} for row in self.data\n",
    "        ]\n",
    "\n",
    "        self.people_dict = {d['ID']: d for d in people}\n",
    "\n",
    "        for person in people:\n",
    "            for key in ['Interests','Service_Line_Preference']:\n",
    "                person[key] = set(person[key].split(';'))\n",
    "            self.people_dict[person['ID']]['Interests_met'] = set()\n",
    "            self.people_dict[person['ID']]['Service_Line_Preference_met'] = set()\n",
    "            self.people_dict[person['ID']]['Levels_met'] = set()\n",
    "            self.people_dict[person['ID']]['Matches'] = list()\n",
    "            \n",
    "            if person['Group'] == 'Graduate':\n",
    "                self.graduates.append(person['ID'])\n",
    "            else:\n",
    "                self.mentors.append(person['ID'])\n",
    "    \n",
    "\n",
    "    def initiate_graph(self):\n",
    "        self.G = nx.Graph()\n",
    "\n",
    "        for person, person_dict in self.people_dict.items():\n",
    "            self.G.add_node(person, group = person_dict['Group'])\n",
    "            \n",
    "            \n",
    "    def update_edge_weights(self):\n",
    "        self.G.remove_edges_from(self.G.edges)\n",
    "        for g_id in self.graduates:\n",
    "            for m_id in self.mentors:\n",
    "\n",
    "                # skip if already a match\n",
    "                if m_id in self.people_dict[g_id]['Matches'] :\n",
    "                    continue\n",
    "\n",
    "                # add an edge between all mentors and graduates\n",
    "                self.G.add_edge(g_id, m_id, weight = -1)\n",
    "                \n",
    "                # add weight to all edges where there is shared interest (less if already matched it)\n",
    "                self.G[g_id][m_id]['weight'] -= self.interest_weight * len(self.people_dict[g_id]['Interests'].intersection(self.people_dict[m_id]['Interests']))\n",
    "                self.G[g_id][m_id]['weight'] -= self.interest_met_weight * len(self.people_dict[g_id]['Interests_met'].intersection(self.people_dict[m_id]['Interests']))\n",
    "\n",
    "                # add weight to edges where mentor is in preferred service line (less if already matched it)\n",
    "                self.G[g_id][m_id]['weight'] -= self.service_line_weight * (1 * self.people_dict[m_id]['Service_Line'] in self.people_dict[g_id]['Service_Line_Preference'])\n",
    "                self.G[g_id][m_id]['weight'] -= self.service_line_met_weight * (1 * self.people_dict[m_id]['Service_Line'] in self.people_dict[g_id]['Service_Line_Preference_met'])\n",
    "\n",
    "                # remove weight from edges where the level has been matched\n",
    "                self.G[g_id][m_id]['weight'] += self.level_matched_penalty if self.people_dict[m_id]['Level'] in self.people_dict[g_id]['Levels_met'] else 0\n",
    "\n",
    "                # add weight to edges where a mentor has less than average match\n",
    "                match_comparison = math.floor(len(self.graduates)/len(self.mentors) * self.num_matches)\n",
    "                self.G[g_id][m_id]['weight'] -= self.lonely_mentor_weight * (1 * (len([match for match in self.people_dict[m_id]['Matches'] if match != '']) <= match_comparison))\n",
    "             \n",
    "            \n",
    "    def find_match(self):\n",
    "        # find the match the minimises weights matching every node possible but maximum once per node\n",
    "        matching = nx.algorithms.bipartite.minimum_weight_full_matching(self.G, top_nodes = None, weight = 'weight')\n",
    "        \n",
    "        self.num_matches += 1\n",
    "        \n",
    "        tracking_matches = set()\n",
    "        \n",
    "        for key, value in matching.items():\n",
    "            g_id, m_id = sorted((key, value), key = lambda x: self.people_dict[x]['Group'] != 'Graduate')\n",
    "\n",
    "            coffee_date = (g_id, m_id)\n",
    "            \n",
    "            if coffee_date in tracking_matches:\n",
    "                continue\n",
    "            \n",
    "            # else\n",
    "            tracking_matches.add(coffee_date)\n",
    "            \n",
    "            # find shared interests and service line preferences\n",
    "            shared_interests = '; '.join(list(self.people_dict[g_id]['Interests'].intersection(self.people_dict[m_id]['Interests'])))\n",
    "            preferred_service_line = '; '.join(list(self.people_dict[g_id]['Service_Line_Preference'].intersection({self.people_dict[m_id]['Service_Line']})))\n",
    "\n",
    "    \n",
    "            self.matches.append([\n",
    "                'Week '+str(self.num_matches),\n",
    "                g_id+': '+self.people_dict[g_id]['Name'],\n",
    "                m_id+': '+self.people_dict[m_id]['Name'],\n",
    "                self.people_dict[m_id]['Service_Line'],\n",
    "                self.people_dict[m_id]['Level'],\n",
    "                shared_interests,\n",
    "                preferred_service_line\n",
    "            ])\n",
    "\n",
    "            # update people_dict\n",
    "            self.people_dict[g_id]['Matches'].append(m_id)\n",
    "            self.people_dict[m_id]['Matches'].append(g_id)\n",
    "\n",
    "            self.people_dict[g_id]['Interests_met'].update(self.people_dict[g_id]['Interests'].intersection(self.people_dict[m_id]['Interests']))\n",
    "            self.people_dict[g_id]['Service_Line_Preference_met'].update(self.people_dict[g_id]['Service_Line_Preference'].intersection({self.people_dict[m_id]['Service_Line']}))\n",
    "            self.people_dict[g_id]['Levels_met'].add(self.people_dict[m_id]['Level'])\n",
    "        \n",
    "        for mentor in self.mentors:\n",
    "            if len(self.people_dict[mentor]['Matches']) < self.num_matches:\n",
    "                self.people_dict[mentor]['Matches'].append('')\n",
    "            \n",
    "            \n",
    "    def evaluate(self):\n",
    "        count_attr = lambda grad, key: len(self.people_dict[grad][key])\n",
    "        \n",
    "        # num interests\n",
    "        interests_met = [count_attr(grad, 'Interests_met') for grad in self.graduates]\n",
    "        interests = [count_attr(grad, 'Interests') for grad in self.graduates]\n",
    "        \n",
    "        # num service line met\n",
    "        service_lines_met = [count_attr(grad, 'Service_Line_Preference_met') for grad in self.graduates]\n",
    "        service_lines = [count_attr(grad, 'Service_Line_Preference') for grad in self.graduates]\n",
    "        \n",
    "        # num levels\n",
    "        levels = [count_attr(grad, 'Levels_met') for grad in self.graduates]\n",
    "        \n",
    "        # num matches for mentors\n",
    "        mentor_matches = [len(list(filter(lambda x: x != '', self.people_dict[mentor]['Matches']))) for mentor in self.mentors]\n",
    "        \n",
    "        overall_interests_met = [\n",
    "            num_intrs + num_sls for num_intrs, num_sls in zip(interests_met, service_lines_met)\n",
    "        ]\n",
    "        \n",
    "        overall_interests = [\n",
    "            num_intrs + num_sls for num_intrs, num_sls in zip(interests, service_lines)\n",
    "        ]\n",
    "        \n",
    "        overall_interests_pct = [\n",
    "            num_met / num_total for num_met, num_total in zip(overall_interests_met, overall_interests)\n",
    "        ]\n",
    "        \n",
    "        # set up grid of graphs\n",
    "        fig, ((left_top, mid_top, right_top), (left_bot, mid_bot, right_bot)) = plt.subplots(2,3, figsize = (16, 6)) \n",
    "        \n",
    "        # interests met graph\n",
    "        left_top.set_title('% Interests met')\n",
    "        left_top.hist(overall_interests_pct)\n",
    "        left_bot.boxplot(overall_interests_pct)\n",
    "        \n",
    "        # different levels met\n",
    "        mid_top.set_title('# levels')\n",
    "        mid_top.hist(levels)\n",
    "        mid_bot.boxplot(levels)\n",
    "        \n",
    "        # number of matches each mentor has\n",
    "        right_top.set_title('# Mentor matches')\n",
    "        right_top.hist(mentor_matches)\n",
    "        right_bot.boxplot(mentor_matches)\n",
    "        \n",
    "        plt.draw()\n",
    "        \n",
    "        # print min and average statistics     \n",
    "        print('Field', 'min','average', sep=' | ')\n",
    "        print('_________________________________')\n",
    "        print('Overall interests', np.min(overall_interests_pct), np.average(overall_interests_pct), sep=' | ')\n",
    "        print('levels', np.min(levels), np.average(levels), sep=' | ')\n",
    "        print('mentor matches', np.min(mentor_matches), np.average(mentor_matches), sep=' | ')\n",
    "        \n",
    "        \n",
    "    def display_week_matches(self, week):\n",
    "        subset = [(row[1].split(':')[0],row[2].split(':')[0]) for row in self.matches if row[0].lower() == week.lower()]\n",
    "\n",
    "        # output matches\n",
    "        grad_set = nx.bipartite.sets(self.G)[0]\n",
    "        pos = nx.bipartite_layout(self.G, grad_set)\n",
    "        node_colours = ['k' if node[1] == 'Graduate' else 'b' for node in self.G.nodes(data = 'group')]\n",
    "        nx.draw_networkx(self.G, node_color = node_colours, pos=pos, edgelist=subset)\n",
    "    \n",
    "    \n",
    "    def output_match_list(self, filename):\n",
    "        with open(filename,'w') as fh:\n",
    "            writer = csv.writer(fh, delimiter = ',')\n",
    "            writer.writerow(self.output_headers)\n",
    "            writer.writerows(self.matches)\n",
    "            \n",
    "            \n",
    "    def output_registration_list(self, filename):\n",
    "        with open(filename, 'w') as fh:\n",
    "            writer = csv.writer(fh, delimiter = ',')\n",
    "            registration_list_header = self.header.copy()\n",
    "            for i in range(self.num_matches):\n",
    "                registration_list_header.append('Week {}'.format(i+1))\n",
    "            writer.writerow(registration_list_header)\n",
    "            for row in self.data:\n",
    "                row_id = row[0]\n",
    "                match_ids = self.people_dict[row_id]['Matches']\n",
    "                match_names = ['' if m_id == '' else m_id + ': '+self.people_dict[m_id]['Name'] for m_id in match_ids]\n",
    "                writer.writerow(row+match_names)\n",
    "\n",
    "                \n",
    "    def output_interests_and_service_line_data(self):\n",
    "        header_interest = ['ID', 'Group', 'Service Line', 'Level', 'Interest']\n",
    "        interests = []\n",
    "        header_service_line_preferences = ['ID', 'Group', 'Service Line', 'Level', 'Service Line Preference']\n",
    "        service_line_preferences = []\n",
    "        for person in self.people_dict.values():\n",
    "            \n",
    "            for interest in person['Interests']:\n",
    "                interests.append([\n",
    "                    person['ID'],\n",
    "                    person['Group'],\n",
    "                    person['Service_Line'],\n",
    "                    person['Level'],\n",
    "                    interest\n",
    "                ])\n",
    "            \n",
    "            for sl_preference in person['Service_Line_Preference']:\n",
    "                service_line_preferences.append([\n",
    "                    person['ID'],\n",
    "                    person['Group'],\n",
    "                    person['Service_Line'],\n",
    "                    person['Level'],\n",
    "                    sl_preference\n",
    "                ])\n",
    "                \n",
    "        with open('interests.csv', 'w') as fh:\n",
    "            writer = csv.writer(fh, delimiter = ',')\n",
    "            writer.writerow(header_interest)\n",
    "            writer.writerows(interests)\n",
    "            \n",
    "        with open('service_line_preferences.csv', 'w') as fh:\n",
    "            writer = csv.writer(fh, delimiter = ',')\n",
    "            writer.writerow(header_service_line_preferences)\n",
    "            writer.writerows(service_line_preferences)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e0e127",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coff = Coffee_Roulette('registrations.csv')\n",
    "\n",
    "# defaults\n",
    "'''\n",
    "Coff.interest_weight = 1.0\n",
    "Coff.interest_met_weight = 0.5\n",
    "Coff.service_line_weight = 1.0\n",
    "Coff.service_line_met_weight = 0.5\n",
    "Coff.level_matched_penalty = 0.6\n",
    "Coff.lonely_mentor_weight = 2.0\n",
    "'''\n",
    "\n",
    "for i in range(4):\n",
    "    Coff.update_edge_weights()\n",
    "    Coff.find_match()\n",
    "Coff.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9809b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coff = Coffee_Roulette('registrations.csv')\n",
    "    \n",
    "Coff.interest_weight = 0\n",
    "Coff.interest_met_weight = 0\n",
    "Coff.service_line_weight = 0\n",
    "Coff.service_line_met_weight = 0\n",
    "Coff.level_matched_penalty = 0\n",
    "Coff.lonely_mentor_weight = 0\n",
    "    \n",
    "for i in range(4):\n",
    "    Coff.update_edge_weights()\n",
    "    Coff.find_match()\n",
    "Coff.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coff = Coffee_Roulette('registrations.csv')\n",
    "    \n",
    "Coff.interest_weight = 1\n",
    "Coff.interest_met_weight = 0\n",
    "Coff.service_line_weight = 1\n",
    "Coff.service_line_met_weight = 0\n",
    "Coff.level_matched_penalty = 0\n",
    "Coff.lonely_mentor_weight = 0\n",
    "    \n",
    "for i in range(4):\n",
    "    Coff.update_edge_weights()\n",
    "    Coff.find_match()\n",
    "Coff.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coff = Coffee_Roulette('registrations.csv')\n",
    "    \n",
    "Coff.interest_weight = 1\n",
    "Coff.interest_met_weight = 0\n",
    "Coff.service_line_weight = 1\n",
    "Coff.service_line_met_weight = 0\n",
    "Coff.level_matched_penalty = 1\n",
    "Coff.lonely_mentor_weight = 0\n",
    "    \n",
    "for i in range(4):\n",
    "    Coff.update_edge_weights()\n",
    "    Coff.find_match()\n",
    "Coff.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coff = Coffee_Roulette('registrations.csv')\n",
    "    \n",
    "Coff.interest_weight = 1\n",
    "Coff.interest_met_weight = 0\n",
    "Coff.service_line_weight = 1\n",
    "Coff.service_line_met_weight = 0\n",
    "Coff.level_matched_penalty = 1\n",
    "Coff.lonely_mentor_weight = 1.5\n",
    "    \n",
    "for i in range(4):\n",
    "    Coff.update_edge_weights()\n",
    "    Coff.find_match()\n",
    "Coff.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c889cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coff.output_match_list('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coff.output_registration_list('registration_list_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b99a761",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coff.output_interests_and_service_line_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
